[{"categories":["论文"],"content":"SVo论文翻译","date":"2021-11-16","objectID":"/zh-cn/svo/","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"SVO：快速的半直接单目视觉里程计 摘要：我们提出了一种半直接单目视觉里程计算法，它比当前最先进的方法精确、稳健且速度更快。半直接法消除了运动估计中昂贵的特征提取和匹配技术的需要，直接在像素级上操作，做到了在高帧率下的亚像素精度（subpixel precision），以及采用概率建图（probabilistic mapping）方法对异常测量值进行显式建模，从而得到较少的异常值和更可靠的点。精确的高帧率运动估计在纹理较少、重复性和高频的场景中具有更强的鲁棒性。该算法应用于GPS无效环境下的无人机状态估计，在嵌入式计算机上以每秒55帧的速度运行，在消费型笔记本电脑上以每秒300帧以上的速度运行。我们将我们的方法称为SVO（半直接视觉里程计）。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:0:0","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"I. 引言  微型飞行器 (MAV) 很快将在灾害管理、工业检测和环境保护方面发挥重要作用。对于此类操作，仅基于 GPS 信息进行导航是不够的。 精确的完全自主操作需要 MAV 依赖替代定位系统。 因此，为了最小的重量和功耗，[1]-[5]建议仅使用一个向下看的相机与惯性测量单元结合使用。这种设置允许在室外区域完全自主的航点跟踪[1]-[3]以及 MAV 和地面机器人之间的协作[4] [5]。  据我们所知，所有用于 MAV 的单目视觉里程计 (VO) 系统[1] [2] [6] [7]都是基于特征的。然而，在 RGB-D 和基于立体的 SLAM 系统中，基于光度误差最小化的直接方法 [8]-[11]正变得越来越流行。  在这项工作中，我们提出了一种半直接 VO，它将基于特征的方法（跟踪许多特征、并行跟踪和映射、关键帧选择）的成功因素与直接方法的准确性和速度相结合。 MAV 的高帧率 VO 有望提高稳健性和更快的飞行机动。  这项工作的开源实现和视频可在以下网址获得：http://rpg.ifi.uzh.ch/software。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:1:0","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"A. 视觉运动估计方法的分类  同时从视频中恢复相机姿态和场景结构的方法可以分为两类:  a) 特征法：标准方法是在每个图像中提取一组稀疏的显着图像特征（例如点、线）；使用不变特征描述符在连续帧中匹配它们；使用对极几何稳健地恢复相机运动和结构；最后，通过重投影误差最小化来细化姿势和结构。大多数 VO 算法[12]遵循此程序，独立于应用的优化框架。这些方法成功的一个原因是强大的特征检测器和描述符的可用性，即使在较大的帧间移动时，它们也允许图像之间的匹配。基于特征的方法的缺点是依赖检测和匹配阈值，需要稳健的估计技术来处理错误的对应关系，以及大多数特征检测器针对速度而不是精度进行优化的事实，这样运动估计的漂移 必须通过对许多特征测量进行平均来补偿。  a) 直接法：直接方法[13]直接从图像中的光强值估计结构和运动。与仅考虑到某些特征位置的距离的基于特征，局部强度梯度幅度和方向用于优化的方法相比。直接方法利用图像中所有信息，即使来自梯度很小的区域，且已被证明在具有很少纹理的场景[14]或在相机散焦和运动模糊的情况下的鲁棒性方面优于基于特征的方法[15]。光度误差的计算比重投影误差更密集，因为它涉及扭曲和整合大图像区域。 然而，由于直接方法直接对图像的强度值进行操作，因此可以节省特征检测和不变描述符计算的时间。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:1:1","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"B. 相关工作  与[1] [2] [7]相比，大多数用于 MAV 的单目VO算法都依赖于PTAM[16]。PTAM是一种基于特征的SLAM算法，通过跟踪和映射许多（数百）特征来实现鲁棒性。同时，它通过并行运动估计和映射任务，并依靠高效的基于关键帧的束调整（BA）实时运行[17]。然而，PTAM是为小型桌面场景中的增强现实应用而设计的，需要进行多次修改（例如，限制关键帧的数量），以允许在大规模室外环境中操作[2]。  早期的直接单目SLAM方法跟踪并绘制了少数有时手动选择的平面面片[18]–[21]。第一种方法[18] [19]使用滤波算法来估计结构和运动，而后来的方法[20]–[22]使用非线性最小二乘优化。所有这些方法都是估计补丁的表面法线，这允许在广泛的视点范围内跟踪面片，从而大大减少估计中的漂移。文章[19]–[21]的作者实现了实时性能，但是，只有少数选定的平面区域和小数据集具有实时性能。文章[22]中提出了一种用于车载全向摄像机的VO算法。在[8]中，放松了局部平面性假设，并提出了针对立体相机计算的任意三维结构的直接跟踪。在[9]-[11]中，同样的方法也适用于RGB-D传感器。在DTAM[15]中，引入了一种新的直接方法，该方法通过最小化全局空间正则化能量泛函数来计算每个关键帧的密集深度图。通过使用深度贴图直接对齐整个图像，可以找到相机的姿势。这种方法的计算强度非常高，只有通过GPU的大量并行才能实现。为了减少计算需求，文章[23]中描述的方法，在本工作的审查过程中发表，只使用强梯度的像素。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:1:2","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"C. 贡献与概要  我们提出的半直接视觉里程计（SVO）算法采用特征对应，然而特征响应是直接运动估计的隐式结果，而不是显式特征提取和匹配的结果。因此只有在选择关键帧初始化新的3D点时，才需要进行特征提取(见图1)。其优点是通过减少每帧的特征提取而提高了速度，通过亚像素特征对应提高了精度。与以前的直接方法相比，我们使用许多(数百)小块而不是少数(数十)大平面块[18]-[21]。使用许多小面片可以增强鲁棒性，并允许忽略面片法线。提出的用于运动估计的基于稀疏模型的图像对齐算法与基于模型的稠密图像对齐相关[8]–[10] [24]。然而，我们证明了稀疏的深度信息足以获得运动的粗略估计并找到特征对应。一旦建立了特征对应和摄像机姿态的初始估计，该算法将继续只使用点特征，因此名称为“半直接”。这种转换允许我们依赖快速和建立的框架来调整BA（例如[25]）。  使用显式建模离群测量值的贝叶斯过滤器来估计特征位置处的深度。仅当相应的深度过滤器已收敛时，才在地图中插入3D点，这需要多次测量。结果是一张地图，只有很少的异常值以及很多可以可靠跟踪的点。  本文的贡献是: 一种新的半直接VO方法，它比目前最先进的 MAV 更快、更准确; 集成了一种概率映射方法，对异常值测量具有鲁棒性。  第二节概述了方法，第三节介绍了一些必要的符号，第四节和第五节解释了提出的运动估计和映射算法，第七节提供了实验结果和比较。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:1:3","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"II. 系统概述  图1 提供了 SVO 的概述。该算法使用两个并行线程（如[16]），一个用于估计相机的运动，另一个用于在探索环境时进行映射。这种分离允许在一个线程中进行快速和恒定的时间跟踪，而第二个线程扩展映射，与硬实时约束解耦。  运动估计线程实现了所提出的相对姿态估计的半直接方法。第一步是通过基于 parse 模型的图像对齐进行姿势初始化：通过最小化与相同3D点的投影位置对应的像素之间的光度误差来找到相对于前一帧的相机姿态（见图2）。下一步通过对齐对应的特征片来细化重投影点对应的2D坐标（见图3）。运动估计通过最小化前面特征对齐步骤中引入的重投影误差来细化姿态和结构。  在建图线程中，为每个要估计相应3D点的2D特征初始化一个概率深度过滤器。只要在图像中很少发现3D到2D对应的区域中选择了新的关键帧，就会初始化新的深度过滤器。过滤器在深度上具有很大的不确定性。在随后的每一帧，深度估计都以贝叶斯方式更新（见图5）。当深度过滤器的不确定性足够小时，将在地图中插入一个新的3D点，并立即用于运动估计。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:2:0","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"III. 标记  在详细介绍算法之前，我们简要定义了本文中使用的符号。  在时间步长 $k$ 采集的强度图像用 $I_k$ 表示：$\\Omega \\subset \\mathbb{R}^2 \\mapsto \\mathbb{R}$，在这里 $\\Omega$ 是图像域。任意三维点$\\mathbf{p}=(x, y, z)^{\\top} \\in \\mathcal{S}$ 在可见场景曲面上 $\\mathcal{S}$ 通过摄像机投影模型$\\pi ：\\mathbb{R}^3 \\mapsto \\mathbb{R}^2$ 映射到图像坐标 $\\mathbf{u}=(u,v)^{\\top} \\in \\Omega$ ： $$ \\mathbf{u}=\\pi\\left({ }_{k} \\mathbf{p}\\right) {\\tag 1} $$ 其中 $k$ 表示点坐标是相机参考帧 $k$ 中的。投影 $\\pi$ 由通过校准已知的固有摄像机参数确定。给定逆投影函数 $\\pi^{-1}$ 和深度 $d_\\mathbf{u} \\in \\mathcal{R}$，可以恢复与图像坐标对应的3D点: $$ {}_k\\mathbf{p} = \\pi^{-1}(\\mathbf{u},d_\\mathbf{u}) {\\tag 2} $$ 其中 $\\mathcal{R} \\subseteq \\Omega$ 域是深度已知的。  在时间 $k$ 相机的位置与方向使用刚体变换 $T_{k,w} \\in SE(3)$ 表示。它允许我们将一个3D点从世界坐标系映射到相机坐标系：${}_k\\mathbf{p} = T_{k,w} · {}_w\\mathbf{p}$ 。两个连续帧之间的相对变换可用$T_{k,k−1}=T_{k,w}·T^{−1}_{k−1,w}$ 来计算。在优化过程中，我们需要一个最小的变换表示，因此，在恒等式处使用对应于切空间 $SE(3)$ 的李代数 $\\mathfrak{s e}(3)$。我们用 $\\xi =(ω，ν)^T \\in \\mathbb{R}^6$ 表示代数元素，也称为扭转坐标，式中ω称为角速度，ν称为线速度。扭转坐标 $\\xi$ 通过指数映射[26]映射到 $SE(3)$： $$ \\mathbf T(\\xi) = \\exp (\\hat{\\xi}) {\\tag 3} $$ ","date":"2021-11-16","objectID":"/zh-cn/svo/:3:0","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"IV. 运动估计  SVO使用直接方法计算相对摄像机运动和特征对应的初始猜测，并基于特征的非线性重投影误差细化。下面将详细介绍每个步骤，并在 图2 到 图4 中进行说明。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:4:0","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"A. 基于稀疏模型的图像对齐  两次连续的相机的位姿变换 $\\mathbf T_{k,k-1}$ 的最大似然估计是最小化强度残差的负对数似然： $$ \\mathbf{T}_{k, k-1}=\\arg \\min _{\\mathbf{T}} \\iint_{\\overline{\\mathcal{R}}} \\rho[\\delta I(\\mathbf{T}, \\mathbf{u})] d \\mathbf{u} {\\tag 4} $$ 定义强度残差 $\\delta I$ 为对同一3D点的像素之间光度差。它可以通过从之前的图像 $I_{k-1}$ 一个2D点反向投影，然后将其投影到当前的相机视图来计算： $$ \\delta I(\\mathbf{T}, \\mathbf{u})=I_{k}\\left(\\pi\\left(\\mathbf{T} \\cdot \\pi^{-1}\\left(\\mathbf{u}, d_{\\mathbf{u}}\\right)\\right)\\right)-I_{k-1}(\\mathbf{u}) \\quad \\forall \\mathbf{u} \\in \\overline{\\mathcal{R}} {\\tag 5} $$ 其中 $\\mathcal{R}$ 是指其深度 $d_{\\mathbf u}$ 在 $k-1$ 时间已知，且投影点在当前图像可见的图像域： $$ \\overline{\\mathcal{R}}=\\lbrace\\mathbf{u} \\mid \\mathbf{u} \\in \\mathcal{R}_{k-1} \\wedge \\pi\\lparen\\mathbf{T} \\cdot \\pi^{-1}\\lparen\\mathbf{u}, d_{\\mathbf{u}}\\rparen \\rparen \\in \\Omega_k \\rbrace {\\tag 6} $$ 为了简单起见，我们在下面假设强度残差是正态分布的，且具有单位方差。负对数似然极小值对应于最小二乘问题：$\\rho[.] \\hat{=} \\frac{1}{2}|\\cdot|^{2}$ 。实际上，由于遮挡，分布具有较重的尾部，因此必须应用稳健的成本函数[10]。  与以前的工作不同，在以前的工作中，图像中的大区域的深度是已知的[8]–[10] [24]，而我们这里只知道稀疏特征位置 $\\mathbf u_i$ 的深度 $d_\\mathbf {u_i}$。我们用矢量 $\\mathbf I(\\mathbf u_i)$ 表示特征点周围4×4像素的小块。我们试图找到使所有面片的光度误差最小化的相机位姿（见图2）： $$ \\mathbf{T}_{k, k-1}=\\arg \\min _{\\mathbf{T}_{k, k-1}} \\frac{1}{2} \\sum_{i \\in \\overline{\\mathcal{R}}}\\left|\\delta \\mathbf{I}\\left(\\mathbf{T}_{k, k-1}, \\mathbf{u}_{i}\\right)\\right|^{2} {\\tag 7} $$ 由于方程(7)对 $\\mathbf{T}_{k, k-1}$ 是非线性的，我们用迭代高斯-牛顿法求解它。给定一个相对变换的估计 $\\hat {\\mathbf{T}}_{k, k-1}$，该估计的增量更新 $\\mathbf T(\\xi)$ 可以用一个小量 $\\xi \\in \\mathfrak{s e}(3)$ 参数化。我们使用强度残差的逆复合公式[27]，计算时间 $k−1$ 时参考图像的更新步长 $\\mathbf T(\\xi)$: $$ \\delta \\mathbf{I}\\left(\\xi, \\mathbf{u}_{i}\\right)=\\mathbf{I}_{k}\\left(\\pi\\left(\\hat{\\mathbf{T}}_{k, k-1} \\cdot \\mathbf{p}_{i}\\right)\\right)-\\mathbf{I}_{k-1}\\left(\\pi\\left(\\mathbf{T}(\\xi) \\cdot \\mathbf{p}_{i}\\right)\\right) {\\tag 8} $$ 其中 $\\mathbf{p} = \\pi^{-1}(\\mathbf{u},d_\\mathbf{u})$。然后，使用等式（3）将更新步骤的倒数应用于当前估计： $$ \\hat {\\mathbf T}_{k,k-1} \\gets \\hat {\\mathbf T}_{k,k-1} \\cdot \\mathbf T(\\xi)^{-1} {\\tag 9} $$ 注意，我们不会因为计算速度的原因而扭曲补丁。这个假设在帧到帧的小运动和小补丁大小的情况下是有效的。  为了找到最优更新步长 $\\mathbf T(\\xi)$，我们计算(7)的导数并设为零: $$ \\sum_{i \\in \\overline{\\mathcal{R}}} \\nabla \\delta \\mathbf{I}\\left(\\xi, \\mathbf{u}_{i}\\right)^{\\top} \\delta \\mathbf{I}\\left(\\xi, \\mathbf{u}_{i}\\right)=0 $$ 为了解决这个系统，我们将当前状态线性化: $$ \\delta \\mathbf{I}\\left(\\xi, \\mathbf{u}_{i}\\right) \\approx \\delta \\mathbf{I}\\left(0, \\mathbf{u}_{i}\\right)+\\nabla \\delta \\mathbf{I}\\left(0, \\mathbf{u}_{i}\\right) \\cdot \\xi $$ 其中雅克比矩阵 $\\mathbf J_i :=\\nabla \\delta \\mathbf{I}\\left(0, \\mathbf{u}_{i}\\right) $ 具有16×6维度，因为面片大小为4×4，并用链式规则计算： $$ \\frac{\\partial \\delta \\mathbf{I}\\left(\\xi, \\mathbf{u}_{i}\\right)}{\\partial \\xi}=\\left.\\left.\\left.\\frac{\\partial \\mathbf{I}_{k-1}(\\mathbf{a})}{\\partial \\mathbf{a}}\\right|_{\\mathbf{a}=\\mathbf{u}_{i}} \\cdot \\frac{\\partial \\pi(\\mathbf{b})}{\\partial \\mathbf{b}}\\right|_{\\mathbf{b}=\\mathbf{p}_{i}} \\cdot \\frac{\\partial \\mathbf{T}(\\xi)}{\\partial \\xi}\\right|_{\\xi=0} \\cdot \\mathbf{p}_{i} $$ 通过将（11）插入（10）并将雅可比矩阵叠加在矩阵 $\\mathbf J$ 中，我们得到了正规方程： $$ \\mathbf J^{\\top} \\mathbf J \\xi = - \\mathbf J^{\\top} \\delta \\mathbf I(0) {\\tag {12}} $$ 这样可解决更新 $\\xi$。注意，通过使用逆合成方法，可以预先计算雅可比矩阵，因为它在所有迭代中保持恒定(参考面片 $\\mathbf I_{k-1} (\\mathbf u_i)$ 和点 $\\mathbf p_i$ 不变)，这将导致显著的加速[27]。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:4:1","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"B. 通过特征对齐实现松弛  下一步是将相机与前一帧对齐。通过反向投影，找到的相对位姿 $\\mathbf T_{k,k−1}$ 隐式地定义了新图像中所有可见3D点的特征位置的初始猜测。由于3D点的位置不准确，因此相机姿势不准确，因此可以改进这种初始猜测。为了减少漂移，相机的位姿应该与地图对齐，而不是与前一帧对齐。  从估计的相机位姿可以将看到的地图的所有3D点都投影到图像中，从而估计出相应的2D特征位置 $\\mathbf u_i^{\\prime}$（见图3）。对于每个重投影的点，将具有最近的观察角度识别为关键帧 $r$ 。然后，特征对齐步骤通过最小化当前图像中的补丁相对于关键帧器中的参考补丁的光度误差来单独优化新图像中的所有2D特征位置 $\\mathbf u_i$： $$ \\mathbf u_i^{\\prime}=\\arg \\min _{\\mathbf u_i^{\\prime}} \\frac{1}{2}\\lVert\\mathbf{I}_{k}(\\mathbf u_i^{\\prime})-\\mathbf A_i \\cdot \\mathbf I_r(\\mathbf u_i)\\rVert^{2}, \\quad \\forall i {\\tag{13}} $$ 这种对齐是用逆合成 Lucas-Kanade 算法[27]来解决的。与前面的步骤相反，我们对参考补丁应用了一个仿射扭曲 $\\mathbf A_i$，因为最近的关键帧通常比前一张图像更远，所以使用了更大的补丁大小（8×8像素）。  这一步可以理解为一个松弛步骤，它违反了极线约束，以实现特征面片之间更高的相关性。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:4:2","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"C. 位姿与结构优化  在前一步中，我们以违反极线约束为代价，建立了具有亚像素精度的特征对应。特别是，我们生成了重投影误残差 $\\lVert \\mathbf \\delta \\mathbf u_i \\rVert = \\lVert \\mathbf u_i - \\pi(\\mathbf T_{k,w} \\enspace {}_w \\mathbf p_i )\\rVert \\neq 0$，平均为 0.3 个像素。在最后一步，我们再一次通过最小化重投影残差来优化相机位姿 $\\mathbf T_{k,w}$： $$ \\mathbf{T}_{k, w}=\\arg \\min _{\\mathbf{T}_{k, w}} \\frac{1}{2} \\sum_{i}\\left|\\mathbf{u}_{i}-\\pi\\left(\\mathbf{T}_{k, w} w \\mathbf{p}_{i}\\right)\\right|^{2} {\\tag {14}} $$ 这是一个众所周知的仅运动 BA 问题，并且可以有效地使用迭代非线性最小二乘最小化算法（如高斯牛顿）来解决。  随后，我们通过最小化重投影误差（structure-only BA）优化观察到的三维点的位置。最后，可以应用局部BA，将所有闭合关键帧的位姿和观察到的三维点共同优化。在算法的快速参数设置中，我们忽略了 BA 步骤（章节VII）。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:4:3","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"D. 讨论  算法的第一个（第IV-A部分）和最后一个（第IV-C部分）优化似乎是多余的，因为两者都优化了相机的6自由度姿态。实际上，我们可以直接从第二步开始，通过 Lucas-Kanade 跟踪所有特征补丁[27]，建立特征响应，然后进行非线性姿态细化（第IV-C节）。虽然这种方法可行，但处理时间会更长。在大距离上跟踪所有功能（例如，30像素）需要一个更大的补丁和金字塔实现。此外，一些特征可能被跟踪不准确，这将需要异常值检测。然而，在SVO中，特征对齐通过在稀疏图像对齐步骤中优化6个参数（相机姿态）来有效地初始化。稀疏图像对齐步骤隐式地满足极线约束，并确保不存在异常值。  有人可能会说，第一步（稀疏图像对齐）将足以估计相机的运动。实际上，这是最近为RGB-D相机开发的算法[10]所做的，然而，通过对齐完整的深度地图而不是稀疏的补丁。我们从经验上发现，与同时使用所有三个步骤相比，使用第一个步骤只会导致更大的漂移。精度的提高是由于新图像相对于关键帧和地图对齐，而稀疏图像对齐仅相对于前一帧对齐新帧。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:4:4","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"V. 建图  给定一幅图像及其位姿 ${ I_k,\\mathbf T_{k,w} }$，建图线程估计对应的未知三维点的二维特征的深度。特征的深度估计采用概率分布建模。每个后续观测 ${ I_k,\\mathbf T_{k,w} }$ 都用于更新贝叶斯框架中的分布（见图5），如[28]所示。当分布的方差变得足够小时，使用（2）将深度估计转换为3D点，该点插入地图并立即用于运动估计（见图1）。在下文中，我们在[28]中报告了基本结果和对原始实现的修改。  每一个深度过滤器都与一个参考关键帧 $r$ 关联。初始化滤波器在深度上为高度不确定性，并将平均值设置为参考帧中的平均场景深度。对于每个后续观测 ${ I_k,\\mathbf T_{k,w} }$，我们在新图像 $I_k$ 的极线上搜索与参考面片具有最高相关性的面片。极线可以从帧 $\\mathbf T_{r,k}$ 和穿过 $\\mathbf u_i$ 的光线之间的相对姿势计算出来。可通过三角测量找到与深度 $\\widetilde {d}_i^k$ 相关最高的相关点 $\\mathbf u^{\\prime}_i$（见图5）。  测量 $\\widetilde {d}_i^k$ 通过 Gaussian + Uniform 混合模型建模分布：一个好的测量是在真实深度周围正态分布的，而一个异常值测量是在区间 $\\lbrack d^{min}_i,d^{max}_i \\rbrack$ 内均匀分布的: $$ p\\left(\\tilde{d}_{i}^{k} \\mid d_{i}, \\rho_{i}\\right)=\\rho_{i} \\mathcal{N}\\left(\\tilde{d}_{i}^{k} \\mid d_{i}, \\tau_{i}^{2}\\right)+\\left(1-\\rho_{i}\\right) \\mathcal{U}\\left(\\tilde{d}_{i}^{k} \\mid d_{i}^{\\min }, d_{i}^{\\max }\\right) $$ 其中 $\\rho_{i}$ 是一个好的测量的概率，$\\tau_{i}^{2}$ 是一个好的测量的方差，可以通过假设图像平面中的一个像素的光度差异方差进行几何计算[29]。  在[28]中详细描述了该模型的递归贝叶斯更新步骤。与[28]相反，我们使用反向深度坐标来处理较大的场景深度。  本文提出的深度估计方法在仅搜索当前极线深度估计的一小段范围时是非常有效的；在我们的例子中，这个范围相当于当前深度估计的两倍标准差。图6 展示了只需很少的运动就可以显著降低深度的不确定性。与标准的从两个角度对点进行三角测量相比，提出的方法的主要优点是，我们观察到的离群值要少得多，因为每个滤波器都要经过许多测量直到收敛。此外，错误的测量被明确地建模，这允许深度收敛，即使在高度相似的环境。在[29]中，我们将演示如何将相同的方法用于稠密建图。 ","date":"2021-11-16","objectID":"/zh-cn/svo/:5:0","tags":["翻译","论文","SLAM"],"title":"SVO译","uri":"/zh-cn/svo/"},{"categories":["论文"],"content":"DSO论文翻译","date":"2021-10-12","objectID":"/zh-cn/dso/","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"Direct Sparse Odometry：直接稀疏里程计 摘要：我们提出了一个新颖的直接稀疏里程计方法（DSO）。整个系统结合了一个完全直接的概率模型（最小化光度误差），并对所有的模型参数进行优化，包括在参考帧中表示为反深度的几何图形和相机运动。为了达到实时运算，算法去除了直接法添加先验的做法，取而代之的是从整个图像上均匀的采样关键点。因为我们的方法不依赖关键点检测或描述符，所以它可以自然地从所有具有强梯度的图像区域中采样像素，包括边缘或平滑的光度变化区域（大多在白色墙壁）。该模型集成了一个完整的光度校准，包括曝光时间、透镜光晕和非线性响应函数（这些基本上都是相机的参数）。我们在三个数据集，包括几个小时的视频上全面评估了我们的方法。实验表明，在各种现实环境下，该方法在跟踪精度和鲁棒性方面都显著优于最先进的直接和间接方法。 ","date":"2021-10-12","objectID":"/zh-cn/dso/:0:0","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"1. 引言  同时定位和建图（SLAM）和视觉里程计（VO）是许多新兴技术的基本组成部分——从自动驾驶汽车和无人机到虚拟现实和增强现实。近年来，SLAM和VO的实时方法取得了重大进展。虽然长期以来该领域由基于特征的（间接）方法主导，但近年来，许多不同的方法越来越受欢迎，即直接和密集方法。 图1. 直接稀疏里程计(DSO)。围绕建筑物循环的1:40分钟视频的3D重建和跟踪轨迹（仅限单目视觉里程计）。左下角插图显示了起点和终点的特写，可视化了轨迹过程中累积的漂移。底行显示一些视频帧。 直接 vs. 间接：所有公式的基础是一个概率模型，该模型将噪声测量 Y 作为输入，并计算未知的隐藏模型参数X（3D世界模型和相机动作）的估计量 。通常使用最大似然方法，该方法找到使获得实际测量值的概率最大化的模型参数，即，$\\mathbf{X}^{*}:=\\operatorname{argmax}_{\\mathbf{X}} P(\\mathbf{Y} \\mid \\mathbf{X})$。  间接方法分两步进行。 首先，对原始传感器测量进行预处理以生成中间表示，解决整体问题的一部分，例如建立对应关系。 其次，计算出的中间值被解释为概率模型中的噪声测量 Y，以估计几何和相机运动。 请注意，第一步通常是通过提取和匹配一组稀疏的关键点来实现的——但是也存在其他选项，例如以密集、正则化的光流的形式建立对应关系。它还可以包括提取和匹配其他几何原语(如线段或曲线段)的参数表示的方法。  直接方法跳过预处理步骤，直接使用实际传感器值（在特定时间段内从特定方向接收到的光）作为概率模型中的测量值 Y。  在被动视觉的情况下，因为传感器提供光度测量，直接方法因此优化了光度误差。另一方面，间接方法优化几何误差，因为预先计算的值（点位置或流向量）是几何量。请注意，对于其他传感器模式，如深度相机或激光扫描仪（直接测量几何量），直接公式也可以优化几何误差。 稠密 vs. 稀疏：稀疏方法仅使用和重建一组选定的独立点（传统上是角点），而密集方法尝试使用和重建 2D 图像域中的所有像素。中间方法（半密集）避免重建完整的表面，但仍旨在使用和重建（主要连接且约束良好的）子集。  然而，除了使用的图像区域的范围之外，一个更基本的——也是重要的——区别在于添加了几何先验。在稀疏公式中，没有邻域的概念，并且几何参数（关键点位置）在给定相机姿势和内在函数的情况下是条件独立的。另一方面，密集（或半密集）方法利用所用图像区域的连通性来制定几何先验，通常有利于平滑。事实上，要想仅从被动视觉中观察到稠密的世界模型，就必须要有这样的先验。通常，该先验直接以附加对数似然能量项的形式表示[26,21,22]。  请注意，密集和稀疏之间的区别并不是直接和间接的同义词——事实上，所有四种组合都存在： 稀疏+间接：这是最广泛使用的形式，从一组关键点匹配来估计三维几何，从而使用几何误差而无需几何先验。例如Jin等人的[12]、monoSLAM[4]、PTAM[16]和ORB-SLAM[20]。 稠密+间接：该形式根据密集的正则化光流场或与其结合来估计 3D 几何形状，将几何误差（与流场的偏差）与几何先验（流场的平滑度）相结合，示例包括[27, 23]。 稠密+直接：该公式采用光度误差以及几何先验来估计密集或半密集几何。 示例包括DTAM[21]、其前身[26]和LSD-SLAM[5]。 稠密+直接：这是本文提出的公式。 它优化了直接在图像上定义的光度误差，而不包含几何先验。虽然我们不知道最近有任何使用该公式的工作，但Jin等人在2003年已经提出了一个稀疏和直接的公式[13]。然而，与他们基于扩展卡尔曼滤波器的工作相比，我们的方法使用非线性优化框架。 探索稀疏和直接结合的动机在下一节中阐述。 ","date":"2021-10-12","objectID":"/zh-cn/dso/:1:0","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"1.1 动机 本文提出的单目视觉里程计的直接和稀疏公式是出于以下考虑。  （1）直接：关键点的主要好处之一是它们能够对使用现成的商品相机拍摄的图像中存在的光度和几何失真提供鲁棒性。例如自动曝光变化、非线性响应函数（伽马校正/白平衡）、镜头衰减（渐晕）、去拜耳效应，甚至是滚动快门引起的强烈几何失真。  同时，对于介绍中提到的所有用例，数以百万计的设备将（和已经）配备摄像头，仅用于为计算机视觉算法提供数据，而不是捕获图像供人类消费。这些相机应该并且将被设计为提供完整的传感器模型，并以最适合处理算法的方式捕获数据：例如，自动曝光和伽马校正不是未知的噪声源，而是提供更好图像数据的功能—— 并且可以将其合并到模型中，使获得的数据更具信息性。由于直接方法将完整的图像形成过程建模到像素强度，因此它极大地受益于更精确的传感器模型。  直接公式的主要优点之一是，它不需要点本身可以识别，因此允许更精细的几何表示（像素逆深度）。此外，我们可以从所有可用的数据中取样——包括边缘和弱强度变化——生成一个更完整的模型，并在稀疏纹理环境中提供更强的鲁棒性。 图2. 稀疏与密集 Hessian 结构。左：稀疏束平差的 Hessian 结构：由于几何几何块是对角线，因此可以使用 Schur 补集高效求解。右图：几何先验增加了（部分非结构化的）几何-几何相关性——因此得到的系统不仅要大得多，而且也变得更难解决。为简单起见，我们不显示全局相机内在参数。  （1）稀疏：添加几何先验的主要缺点是在几何参数之间引入了相关性，这使得在统计上一致的实时联合优化不可行（参见图 2）。这就是为什么现有的密集或半密集方法（a）忽略或粗略地近似几何参数（橙色）和/或几何参数和相机姿势（绿色）之间的相关性，以及（b）对密集几何采用不同的优化方法 部分，例如原始对偶公式[26, 21, 22]。  此外，当今先验的表达复杂性是有限的：虽然它们使 3D 重建更密集、局部更准确且更具视觉吸引力，但我们发现先验会引入偏差，从而减少而不是增加长期、大规模的准确性。 请注意，随着时间的推移，随着从现实世界数据中学习到的更现实、无偏见的先验的引入，这很可能会改变。 ","date":"2021-10-12","objectID":"/zh-cn/dso/:1:1","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"1.2 贡献与概要  在本文中，我们提出了一种单目视觉里程计的稀疏直接方法。 据我们所知，它是唯一一种完全直接的方法，可以联合优化所有涉及的模型参数的完全似然性，包括相机姿势、相机内在参数和几何参数（逆深度值）。 这与 SVO[9]等混合方法形成对比，后者恢复为联合模型优化的间接形式。  优化是在滑动窗口中执行的，在滑动窗口中，旧相机姿势以及离开相机视野的点被边缘化，其方式受[17]的启发。对比已经存在的算法，我们的方法充分利用光度相机校准，包括镜头衰减、伽马校正和已知曝光时间。 这种集成的光度校准进一步提高了准确性和稳健性。  我们基于CPU的实现在笔记本电脑上实时运行。我们在三个不同的数据集（包括几个小时的视频）上进行了广泛的评估，结果表明，它在鲁棒性和准确性方面都优于其他最先进的方法（直接和间接）。通过减少设置（更少的点和活动关键帧），它甚至以 5 实时速度运行，同时仍然优于最先进的间接方法。 反过来，在高、非实时设置（更多点和活动关键帧）上，它创建的半密集模型与 LSD-SLAM 的密度相似，但更准确。  本文组织如下：第2节介绍了所提出的直接稀疏模型以及加窗优化方法。具体而言，这包括第2.1节中的几何和光度照相机校准、第2.2节中的模型公式以及第2.3节中的窗口优化。第3节描述了前端：算法中执行数据选择并为高度非凸优化后端提供足够精确的初始化的部分。我们在第4.1节中提供了与其他方法的彻底实验比较。我们还评估了重要参数和新概念的影响，如第4.2节中光度校准的使用。在第4.3节中，我们分析了增加的光度和几何噪声对数据的影响。最后，我们在第5节中提供了一个总结。 ","date":"2021-10-12","objectID":"/zh-cn/dso/:1:2","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"2. 直接稀疏模型  我们的直接稀疏里程计基于最近帧窗口上光度误差的连续优化，同时考虑到用于图像形成的光度校准模型。与现有的直接方法相比，我们联合优化所有涉及的参数（相机内在参数、相机外在参数和逆深度值），有效地执行窗口稀疏束调整的光度等效。我们保留其他直接方法采用的几何表示，即3D点表示为参考系中的逆深度（因此具有一个自由度）。 注意. 在整篇论文中，粗体小写字母 (x) 表示向量，粗体大写字母 (H) 表示矩阵。 标量将由浅色小写字母 (t) 表示，函数（包括图像）将由浅色大写字母 (I) 表示。相机姿态表示为变换矩阵$\\mathbf{T}_{i} \\in \\mathrm{SE}(3)$，变换一个点从世界帧到相机帧。线性化的姿态增量将表示为李代数$x_i \\in \\mathfrak{s e}(3)$，这里稍微滥用符号，我们直接写成向量$x_i \\in \\mathbb{R}^{6}$。我们进一步定义了常用的操作符 ⊞ ：$\\mathfrak{s e}(3) \\times \\mathrm{SE}(3) \\rightarrow \\mathrm{SE}(3)$使用左乘公式，即： $$ \\boldsymbol{x}_i \\text { ⊞ } \\mathbf{T}_i:=e^{\\widehat{\\boldsymbol{x}_i}} \\cdot \\mathbf{T}_i $$ ","date":"2021-10-12","objectID":"/zh-cn/dso/:2:0","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"2.1 校准  直接方法全面建模图像形成过程。 除了几何相机模型（包括将 3D 点投影到 2D 图像上的功能）之外，考虑光度相机模型也是有益的，该模型包括将传感器上的像素（辐照度）接收到的真实世界能量映射到相应的强度值的功能。请注意，对于间接方法，这没有什么好处，因此被广泛忽略，因为常见的特征提取器和描述符对光度变化是不变的（或高度鲁棒的）。 2.1.1 几何相机校准  为简单起见，我们为众所周知的针孔相机模型制定了我们的方法——在预处理步骤中去除了径向失真。虽然对于广角相机，这确实会减少视野，但它允许对仅实现有限相机型号选择的方法进行比较。在本文中，我们将投影表示为 $\\Pi_{\\mathrm{c}}: \\mathbb{R}^3 \\rightarrow \\Omega$ 和反投影 $\\Pi_{\\mathbf{c}}^{-1}: \\Omega \\times \\mathbb{R} \\rightarrow \\mathbb{R}^3$，其中 c 表示相机的固有参数（对于针孔模型，它们是焦距和主点）。请注意，类似[2]，我们的方法可以扩展到其他(可逆)相机模型，尽管这确实增加了计算需求。 2.1.2 光度相机校准  我们使用[8]中使用的图像形成模型，它解释了非线性响应函数 $G: \\mathbb{R} \\rightarrow[0,255]$，以及镜头衰减（渐晕）$V: \\Omega \\rightarrow[0,1]$。图3显示了来自 TUM monoVO 数据集的示例校准。 组合模型由下式给出： $$ I_{i}(\\mathrm{x})=G\\left(t_{i} V(\\mathrm{x}) B_{i}(\\mathrm{x})\\right){\\tag 2} $$ 其中 $B_i$ 和 $I_i$ 是第 $i$ 帧中的辐照度和观察到的像素强度，$t_i$ 是曝光时间。 该模型是通过光度校正每个视频帧作为第一步来应用的，通过计算: $$ I_{i}^{\\prime}(\\mathrm{x}):=t_{i} B_{i}(\\mathrm{x})=\\frac{G^{-1}\\left(I_{i}(\\mathrm{x})\\right)}{V(\\mathrm{x})} {\\tag 3} $$ 在本文的其余部分中，除非另有说明，否则 $I_i$ 将始终指的是经过光度校正的图像 $I^\\prime_i$ 。 图3. 光度校准。顶部：反向响应函数G-1和用于图1的相机的镜头衰减V。底部：包含室内和室外部分的序列的曝光时间t（毫秒）。请注意，它的变化系数超过500，从0.018到10.5ms。我们没有将这些量视为未知噪声源，而是在光度误差模型中明确地考虑它们 ","date":"2021-10-12","objectID":"/zh-cn/dso/:2:1","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"2.2 模型组成 图4. 残留图案.用于残差计算的模式 Np。右下角的像素被省略以启用 SSE 优化处理。请注意，由于我们每个点有1个未知数（其逆深度），并且不使用正则化器，因此我们需要 |Np| 1，以便在仅优化两帧时对所有模型参数进行良好约束。图19显示了对这种模式如何影响跟踪精度的评估。  我们将参考帧 $I_i$ 中的点 $\\mathbf{p} \\in \\Omega_{i}$ 在目标帧 $I_j$ 中观察到的光度误差定义为小像素邻域上的加权 SSD。我们的实验表明，8 个像素以略微扩展的模式排列（见图 4），可以在评估所需的计算、运动模糊的鲁棒性和提供足够的信息之间取得良好的平衡。请注意，就包含的信息而言，在如此小的像素邻域上评估 SSD 类似于为中心像素添加一阶和二阶辐照度导数常数项（除了辐照度常数项）。即 $$ E_{\\mathbf{p} j}:=\\sum_{\\mathbf{p} \\in \\mathcal{N}_{\\mathbf{p}}} w_{\\mathbf{p}}\\left|\\left(I_{j}\\left[\\mathbf{p}^{\\prime}\\right]-b_{j}\\right)-\\frac{t_{j} e^{a_{j}}}{t_{i} e^{a_{i}}}\\left(I_{i}[\\mathbf{p}]-b_{i}\\right)\\right|_{\\gamma} $$ 其中 $\\mathcal{N}_{\\mathbf{p}}$ 是包含在 SSD 中的像素集合；$t_i$, $t_j$ 是图像 $I_i$,$I_j$ 的曝光时间；$|\\cdot|_{\\gamma}$ 是 Huber 范数。此外，$\\mathbf{p}^{\\prime}$ 代表 $\\mathbf{p}$ 的投影点位置，深度为 $d_{\\mathbf{p}}$，由下式给出: $$ \\mathbf{p}^{\\prime}=\\Pi_{\\mathbf{c}}\\left(\\mathbf{R} \\Pi_{\\mathbf{c}}^{-1}\\left(\\mathbf{p}, d_{\\mathbf{p}}\\right)+\\mathbf{t}\\right) {\\tag 5} $$ 以及 $$ \\left[\\begin{array}{cc} \\mathbf{R} \u0026 \\mathrm{t} \\newline 0 \u0026 1 \\end{array}\\right]:=\\mathrm{T}_{j} \\mathrm{~T}_{i}^{-1} {\\tag 6} $$ 为了让我们的方法在没有已知曝光时间的情况下对序列进行操作，我们包含了一个额外的仿射亮度传递函数，由下式给出$e^{-a_{i}}\\left(I_{i}-b_{i}\\right)$。请注意，与之前的大多数公式[13, 6]相比，标量因子 $e^{-a_{i}}$ 是对数参数化的。这既可以防止它变成负数，又可以避免乘法（即指数增长）漂移引起的数值问题。  除了使用鲁棒的 Huber 惩罚之外，我们还应用了一个梯度相关的加权 $w_p$，由下式给出: $$ w_{\\mathbf{p}}:=\\frac{c^{2}}{c^{2}+\\left|\\nabla I_{i}(\\mathbf{p})\\right|_{2}^{2}} {\\tag 7} $$ 它降低了具有高梯度的像素的权重。这个加权函数可以从概率上解释为在投影点位置 $\\mathbf{p}^{\\prime}$ 上添加小的、独立的几何噪声，并立即边缘化它——近似小的几何误差。总而言之，误差 $E_{pj}$ 取决于以下变量：（1）点的逆深度 $d_{\\mathbf{p}}$；（2）相机内参 $c$；（3）相关帧的姿态$\\mathbf{T}_{i}$,$ \\mathbf{T}_{j}$；（4）它们的亮度传递函数参数 $a_i$，$b_i$，$a_j$，$b_j$。  所有帧和点的完整光度误差由下式给出: $$ E_{\\text {photo }}:=\\sum_{i \\in \\mathcal{F}} \\sum_{\\mathbf{p} \\in \\mathcal{P}_{i}} \\sum_{j \\in \\text { obs }(\\mathbf{p})} E_{\\mathbf{p} j} {\\tag 8} $$ 其中 $i$ 遍历所有帧 $\\mathcal{F}$，$\\mathbf{p}$ 遍历第 $i$ 帧中的所有点 $\\mathcal{P}_{i}$，$j$ 遍历其中点 $\\mathbf{p}$ 可见的所有帧 obs($\\mathbf{p}$)。图 5 显示了生成的因子图：与经典重投影误差的唯一区别是每个残差对主帧位姿的附加依赖性，即每个项依赖于两个帧而不是一个。虽然这向 Hessian 的姿态-姿态块添加了非对角线条目，但在应用 Schur补充来边缘化点参数后，它不会影响稀疏模式。 由此产生的系统可以类似于间接公式求解。请注意，关于两帧姿势的雅可比矩阵通过它们的相对姿势的伴随线性相关。在实践中，当计算 Hessian 或其 Schur 补码时，可以将这个因素从和中提取出来，大大减少了更多变量依赖引起的额外计算。 图5.直接稀疏模型的因子图。四个关键帧和四个点的示例：一个在 KF1，两个在 KF2，一个在 KF4。每个残差项（在方程 (4) 中定义）取决于点的主框架（蓝色）、观察点的框架（红色）和点的逆深度（黑色）。此外，所有项都取决于全局相机内在向量c，其未显示。  如果曝光时间已知，我们进一步添加一个将仿射亮度传递函数拉为零的先验： $$ E_{\\text {prior }}:=\\sum_{i \\in \\mathcal{F}}\\left(\\lambda_{a} a_{i}^{2}+\\lambda_{b} b_{i}^{2}\\right) {\\tag 9} $$ 如果没有可用的光度校准，我们设置 $t_i = 1$ 和 $\\lambda_{a}=\\lambda_{b}=0$，因为在这种情况下，他们需要对相机的（未知）变化的曝光时间进行建模。作为旁注，应该提到的是，如果 $x_i$ 和 $y_i$ 都包含噪声测量值，乘法因子 $a^{*}=\\operatorname{argmax}_a \\sum_{i}\\left(a x_i-y_i\\right)^2$ 的 ML 估计量是有偏差的，在无约束的情况$\\lambda_{a} = 0$下导致 $a$ 漂移。虽然这通常对估计的姿势几乎没有影响，但如果场景只包含很少的、微弱的强度变化，它可能会引入偏差。 点维数. 在所提出的直接模型中，与间接模型中的三个未知数不同，一个点仅由一个参数（参考坐标系中的逆深度）参数化。为了理解这种差异的原因，我们首先注意到，在这两种情况下，3D 点实际上是连续、真实世界 3D 表面上任意定位的离散样本。不同之处在于定义表面上的 2D 位置的方式。在间接方法中，它被隐式定义为点，它（投影到图像中）在使用的角点响应函数中产生最大值。这意味着表面以及点在表面上的位置都是未知数，需要估计。在我们的直接方法中，点被简单地定义为源像素的光线撞击表面的点，因此只剩下一个未知数。除了减少参数的数量外，这自然能使逆深度参数化，在高斯框架中更适合于表示不确定性，而不是对极远点[3]的不确定性。 一致性. 严格来说，所提出的直接稀疏模型确实允许多次使用某些观察值（像素值），而其他的模型则根本不使用。这是因为——尽管我们的点选择策略试图通过在空间中均匀分布点来避免这种情况（参见第 3.2 节）——我们允许点观察重叠，因此依赖于相同的像素值。这尤其发生在纹理很少的场景中，其中所有点都必须从纹理图像区域的一个小子集中选择。然而，我们认为这在实践中的影响可以忽略不计，并且，如果需要，可以通过删除（或降低）使用相同像素值的观察来避免。 ","date":"2021-10-12","objectID":"/zh-cn/dso/:2:2","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"2.3 模型组成  我们遵循Leutenegger等人[17]的方法，使用Gauss-Newton算法优化滑动窗口中的总误差（8），这在速度和灵活性之间进行了很好的权衡。  为了便于表示，我们将 (1) 中定义的算子⊞扩展到所有优化参数——对于 $\\mathrm{SE}(3)$ 以外的参数，它表示常规加法。我们将使用$\\zeta \\in \\mathrm{SE}(3)^{n} \\times \\mathbb{R}^{m}$来表示所有的优化变量，包括相机位姿、仿射亮度参数、反深度值和相机内在函数。与[17]中一样，边缘化依赖于 $\\zeta$ 中的参数的残差将固定在一个切线空间中，在这个切线空间中，有关该参数的任何未来信息(增量更新)都会累积。我们用 $\\zeta_0$ 表示这个切线空间的评估点，并用 $\\boldsymbol{x} \\in \\mathfrak{s e}(3)^{n} \\times \\mathbb{R}^{m}$ 表示积累的增量更新。因此，当前状态估计由 $\\zeta=\\boldsymbol{x}{\\text {⊞ }} \\zeta{0}$ 给出。图 6 显示了不同变量之间的关系。 高斯牛顿优化. 我们计算高斯牛顿系统为: $$ \\mathbf{H}=\\mathbf{J}^{T} \\mathbf{W} \\mathbf{J} \\quad \\text { and } \\quad \\mathbf{b}=-\\mathbf{J}^{T} \\mathbf{W} \\mathbf{r} {\\tag {10}} $$ 其中 $\\mathbf{W} \\in \\mathbb{R}^{n \\times n}$ 是包含权重的对角矩阵，$\\mathbf{r} \\in \\mathbb{R}^{n}$ 是堆叠残差向量，$\\mathbf{J} \\in \\mathbb{R}^{n \\times d}$ 是 $\\mathbf{r}$ 的雅克比矩阵。  请注意，每个点对能量贡献 $\\mathcal{N}_{\\mathbf{p}}$ = 8 个残差。为符号简单起见，我们将在下面只考虑单个残差 $r_k$， ","date":"2021-10-12","objectID":"/zh-cn/dso/:2:3","tags":["翻译","论文","SLAM"],"title":"DSO","uri":"/zh-cn/dso/"},{"categories":["论文"],"content":"ORB-SLAM论文翻译","date":"2021-09-19","objectID":"/zh-cn/orb-slam/","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"ORB-SLAM：一种通用的精确的单目SLAM系统 摘要：本文提出了ORB-SLAM，一种基于特征的单目SLAM系统，其可以实时操作在大小场景、室内室外环境。系统对复杂的剧烈运动具有鲁棒性，允许宽基线的闭环和重定位，且包含完整的自动初始化。基于最近几年的优秀算法之上，我们从头开始设计了一个新颖的系统，它对所有SLAM任务使用相同的特征：追踪、建图、重定位和闭环。合适的选择重建点和关键帧策略的存在使其具有很好的鲁棒性，并能够生成紧凑的可追踪的地图，并且只有当场景内容发生变化地图才改变，从而允许长时间操作。本文从最受欢迎的数据集中提供了27个序列的详尽评估。相对于其他最先进的单目SLAM方法，ORB-SLAM实现了前所未有的性能。为了社会的利益，我们将源代码公开。 关键字：持续建图，定位，单目视觉，识别，同时定位和制图（SLAM）。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:0:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"I.引言  BA提供相机定位的精确估计以及稀疏几何重建[1][2]，以及并且提供了强烈的匹配网络和良好的初始猜测。一段长的时间，这种方法被认为不符合实时性的应用，如视觉VSLAM。VSLAM系统在构建环境的同时需要估计相机的轨迹。现在，我们为了不以过高的计算成本获得准确的结果，实时SLAM算法必须向BA提供以下信息： 在候选图像帧子集中（关键帧）匹配观测的场景特征（地图云点）。 由于关键帧数量的增长，需要做筛选避免冗余。 关键帧和云点健壮的网络配置可以产生精确的结果，换言之，分布良好的关键帧集合和有明显视差、大量回环匹配的观测云点。 关键帧和云点位置的初始估计，采用非线性优化的方法。 在构建局部地图的过程中，优化的关键是获得良好的稳定性。 本系统可以实时执行快速全局优化（比如位姿图）以实现闭环回路。  BA第一次实时应用是在Mouragon等人[3]提出的视觉里程计算法中，其次是在Klein和Murray的突破性工作PTAM[4]算法中。尽管受制于小场景的应用，PTAM算法对关键帧的选择，特征匹配，点的三角化，相机位姿估计，追踪失败后的重定位非常有效。然而，由于缺少闭环检测和对遮挡场景的处理，再加上其视图不变性差，在地图初始化时需要人工干预等多个因素，使得PTAM算法的应用收到了严重的限制。  在本文中，我们基于PTAM算法的主要框架，采用Gálvez-López和Tardós提出的place recognition（场景/位置识别）算法，Strasdat等人提出的scale-aware loop closing（具备尺度感知的闭环检测）算法以及文献[7][8]中的大尺度操作中Covisibility信息的使用，重新设计了一种新的单目SLAM系统ORB-SLAM，本文的贡献主要包括： 对所有的任务采用相同的特征：追踪、地图构建、重定位和闭环检测。这使得我们的系统更有效率、简单可靠。采用的ORB特征[9]在没有GPU的情况下也有很好的实时性，且具有旋转不变性和光照不变性。 算法支持在宽阔环境中实时操作。由于covisibility graph的使用，特征点的跟踪与构图主要集中在局部共视区域，而与全局地图的大小无关。 使用Essential Graph来优化位姿实现回环检测。构建生成树，并由系统、闭环检测链接和covisibility graph的强边缘进行维护。 算法的实时相机重定位具有明显的旋转不变特性和光照不变性。这就使得点跟踪丢失后可以恢复，增强了地图的重用性。 一种新的基于模型选择的自动鲁棒初始化过程，允许创建平面和非平面场景的初始地图。 提出了一种合适的方法来选择地图点云和关键帧，通过严格删选关键帧和地图点，剔除冗余信息，使得特征点的跟踪具备了更好的稳定性，从而增强算法的可持续操作性。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:1:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"II.相关工作 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:2:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"A.位置识别  Williams等人在综述[13]中比较了几种基于景象的位置识别方法，即图像到图像的匹配，这种方法在大环境下比地图到地图或图像到地图的方法更准确。在景象匹配方法中，bags of words（词袋）[14]的使用以其效率很高而脱颖而出，比如概率方法FAB-MAP[15]算法。DBoW2方法[5]则首次使用了BRIEF描述子[16]生成的二进制词袋连同非常高效的FAST特征检测算法[17]，与SURF和SIFT相比，FAST算法的运时间减小了至少一个数量级。然而，尽管系统运行效率高、鲁棒性好，采用BRIEF描述子不具有旋转不变性和尺度不变性，系统只能运行在同一平面内（否则会造成尺度变化） ，闭环检测也只能从相似的视角中进行。在我们之前的工作[11]中，我们提出了一个使用ORB特征检测子[9]的DBoW2位置识别器。ORB特征是具有旋转不变和尺度不变特性的二进制特征，因此，用它生成的快速识别器具有较好的视角不变性。我们在4组不同的数据集上演示了位置识别功能，从10K图像数据库中提取一个候选闭合回路的运算时间少于39毫秒。在本文的工作中，我们提出了一种改进版本的位置识别方法，采用covisibility信息，在检索数据库时返回几个假设情况而不是最好的匹配。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:2:1","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"B.地图初始化  单目SLAM系统需要设计专门的策略来生成初始化地图，因为单幅图像不具备深度信息。解决这个问题的一种方法是一开始跟踪一个已知结构的对象，正如文献[20]。另一个方法是用一个具有高不确定度的逆深度参数[21]来初始化点的深度信息，理想情况下，该参数会在后期逐渐收敛到真值。最近Engel提出的半稠密方法[10]中就采用类似的方法将像素的深度信息初始化为一个随机数值。  如果是从两个视角来初始化特征，就可以采用以下方法：一种是假设局部场景在同一平面内[4]，[22]然后利用Faugeras等人论文[23]中的单应性来重构摄像头相对位姿。另一种是将场景建模为通用情况（不一定为平面），通过Nister提出的五点算法[26]来计算本征矩阵[24][25]，但该方法存在多解的问题。这两种摄像头位姿重构方法在低视差下都没有很好的约束，如果平面场景内的所有点都靠近摄像机的中心，则结果会出现双重歧义[27]。另一方面，非平面场景可以通过线性8点算法[2]来计算基础矩阵，相机的相对位姿就可以无歧义的重构出来。  针对这一问题，我们在本文的第四部分提出了一个新的基于模型选择的自动初始化方法，即对平面场景算法选择单应性矩阵，而对于非平面场景，算法选择基础矩阵。模型选择的综述方法参见Torr等人的论文[28]。基于类似的理论，我们设计了一种启发式初始化算法，算法考虑到在接近退化情况（比如：平面，近平面，或是低视差）下选择基础矩阵进行位姿估计可能存在的问题，则选择单应性计算。在平面的情况下，为了保险起见，如果最终存在双重歧义，则算法避免进行初始化，因为可能会因为错误选择而导致算法崩溃。因此，我们会延迟初始化过程，直到所选的模型在明显的视差下产生唯一的解。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:2:2","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"C.单目SLAM  单目SLAM最初采用滤波框架[20][21][29][30]来建模。在该类方法中，每一帧都通过滤波器联合估计地图特征位置和相机位姿。这样做带来的问题是在处理连续帧图像上对计算资源的浪费和线性误差的累积。而另外一种SLAM框架是基于关键帧的[3][4]，即采用少数筛选过的图像（关键帧）来构建地图，因为构图不再与帧率相关联，因此基于关键帧的SLAM方法不但节省了计算资源，还可以进行高精度的BA优化。Strasdar等人在论文[31]中证明了基于关键帧的单目SLAM方法比滤波器方法在相同的运算代价上定位结果更精确。  基于关键帧的SLAM系统最具代表性可能是由Klein和Murray等人提出的PTAM算法[4]。它第一次将相机追踪和地图构建拆分成两个并行的线程运行，并成功用于小环境的实时增强现实中。后来文献[32]引入边缘特征对PTAM算法进行了改进，在跟踪过程中增加了旋转估计步骤，实现了更好的重定位效果。由于PTAM中的地图云点通过图像区块与FAST角点匹配，因此仅适合于特征跟踪并不适合用于后期的位置识别。而实际上，PTAM算法并没有进行大闭环检测，其重定位也仅是基于关键帧低分辨率缩略图的相关性进行的，因此视角不变性较差。  Strasdat等人在文献[6]中提出了一个基于GPU实现的大尺度单目SLAM系统，其前端采用光流算法，其次用FAST特征匹配和运动BA，以及后端是基于滑动窗口BA。闭环检测通过具有相似性约束（7自由度）的位姿图优化来完成，该方法可以矫正在单目SLAM系统中出现的尺度偏移问题。在本文中，我们也将采用这种7自由度的位姿图优化方法，并将其应用到我们的Essential Graph中，更多细节将在第三部分D节里面描述。  Strasdat等人在文献[7]中采用了PTAM的前端，但其跟踪部分仅在一个从covisibility graph提取的局部图中进行。他们提出了一个双窗口优化后端，在内部窗口中连续进行BA，在有限大小的外部窗口中构建位姿图。然而， 只有当外部窗口尺寸足够大到可以包含整个闭环回路的情况下，闭环检测才能起作用。在我们的算法中，我们利用了Strasdat等人提出的基于covisibility的局部地图的优势，并且通过covisibility map来构建位姿图，同时重新设计前端和后端。另一个区别是，我们并没有用特别的特征提取方法做闭合回路检测（比如SURF方法），而是基于相同的追踪和建图的特征进行位置识别，获得具有鲁棒性的重定位和闭环检测。  在Pirker等人的论文[33]中作者提出了CD-SLAM方法，一个非常复杂的系统，包括闭环检测，重定位，大尺度操作以及对算法在动态环境运行所做的改进。但文中并没有提及地图初始化。因此不利于后期读者对算法的复现，也致使我们没法对其进行精确性、鲁棒性和大场景下的测试对比。  Song等人在论文[34]提出的视觉里程计方法中使用了ORB特征做追踪和处理BA后端滑动窗口。相比之下，我们的方法更加全面，因为他们的算法中没有涉及全局重定位，闭环回路检测，而且地图也不能重用。他们也使用了相机到地面的真实距离来限制单目SLAM算法的尺度漂移。  Lim等人在我们提交本文最初的版本[12]之后发表了论文[25]，他们也采用相同的特征进行跟踪，地图构建和闭环检测。但是，由于Lim等人的算法选择的BRIEF描述子不具备尺度不变性，因此其算法运行受限在平面轨迹上。并且他们的算法仅从上一帧关键帧开始跟踪特征点，因此访问过的地图不能重用，这样的处理方式与视觉里程计很像，存在系统无限增长的问题。我们在第三部分E小节里面与该算法进行了定性比较。  Engel等人在最近的论文[10]里提出了LSD-SLAM算法，其没有采用特征提取和BA方法，而是选择采用直接法（优化也是直接通过图像像素灰度进行）构建了大场景的半稠密地图。算法的结果让人印象深刻，其在没有GPU加速的情况下实时构建了一个半稠密地图，相比基于特征的稀疏地图SLAM系统而言，LSD-SLAM方法在机器人领域有更大的应用潜力。然而，该算法的运行仍然需要基于特征做闭环检测，且相机定位的精度也明显低于PTAM和我们的算法，相关实验结果我们将在第8部分的B小节中展示，对该结果的讨论在文章IX部分B小节进行。  Forster等人在论文[22]中提出了介于直接方式和基于特征的方法之间的半直接视觉里程计算法SVO方法。该方法不需要对每帧图像都提取特征点，且可以以很高的帧率运行，在四轴飞行器上取得了令人惊叹的定位效果。然而，SVO算法没有进行闭环检测，且目前主要基于下视摄像头运行。  最后，我们想讨论一下目前关键帧的选择方法。由于所有的视觉SLAM算法选择所有的云点和图像帧运行BA是不可行的。因此，在论文[31]中，Strasdat等人证明最合理的选择是保留尽可能多地点云和非冗余关键帧。PTAM方法非常谨慎插入关键帧避免运算量增长过大。然而，这种严格限制关键帧插入的策略在算法运行困难的情况下可能会导致追踪失败。在本文中，为了达到更好的稳定性，我们选择一种更为合适的关键帧插入策略，当算法运行困难的时候算法选择尽快的插入关键帧，然后在后期将冗余的关键帧删除以避免额外的计算成本。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:2:3","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"III.系统架构 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:3:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"A. 特征选择  我们系统设计的中心思想是对SLAM系统的构图、跟踪、重定位以及闭环检测等模块都采用相同的特征。这将使得我们的系统更有效率，避免了像以往文章[6][7]一样还需要额外插入一些额外的识别性强的特征以用于后期的闭环检测。我们每张图像的特征提取远少于33毫秒，远小于目前的SIFT算法（300ms）,SURF算法(300ms)，或最近提出的A-KAZE（~100ms）算法。为了使算法的位置识别能力能更加通用化，我们需要提取的特征具备旋转不变性，而BRIEF和LDB不具备这样的特性。  我们选择了我们选择了ORB[9]，其是具有256位描述符的带方向的多尺度FAST角点。他们对于计算和匹配的速度非常快，同时对视角具有旋转不变的特性。这样可以在更宽的基准线上匹配他们，增强了BA的精度。我们已经在论文[11]sup中演示了基于ORB特征的位置识别性能。需要申明的是，虽然本文的方案中采用ORB算法，但所提出的技术并不仅限于该特征。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:3:1","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"B. 三个线程：跟踪，局部地图构建以及回环检测 图1.ORB-SLAM系统框架，图中显示了算法的三个线程——跟踪、局部构图与闭环检测的所有步骤。另外还有场景识别和地图的主要组成部分。   我们的系统，如图1所示，包含三个并行的线程：跟踪，局部地图构建以及回环检测。跟踪线程负责对每帧图像的相机位置进行定位，并决定什么时候插入新的关键帧。我们首先通过与前一帧图像匹配得到初始特征点，然后采用运动BA优化摄像头位姿。如果特征跟丢（比如由于遮挡或是突然运动），则由位置识别模块进行全局重定位。一旦获得最初的相机位姿估计和特征匹配，则使用由系统维护的关键帧的`covisibility graph`提取一个局部可视化地图，如图2(a)、图2(b)所示。然后通过重投影方法搜索当前帧与局部地图点对应的匹配点，并利用所有的匹配点优化当前相机位姿。最后，跟踪线程决定是否插入新的关键帧。所有的跟踪步骤将在第5部分详细阐述。创建初始化地图的新方法将在第4部分进行说明。  局部地图构建模块负责处理新的关键帧，对周围的相机位姿进行局部BA以优化重构。在covisibility graph已连接的关键帧中搜索新的关键帧中ORB特征的匹配点，以此来三角化新的地图点。有时尽管已经创建了新的点云，但是基于跟踪过程中收集的信息，为了保证点云的高质量，可能会根据点云筛选策略临时删除一些点。局部地图构建模块也负责删除冗余的关键帧。我们将在第6章详细说明局部地图构建的步骤。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:3:2","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"C. 地图点云、关键帧及其选择标准 对每个地图点云$p_i$保存以下信息： 它在世界坐标系中的3D坐标$X_{w,i}$。 视图方向$n_i$，即所有视图方向的平均单位向量。（该方向是指连接该点云和其对应观测关键帧光心的射线方向） ORB特征描述子$D_i$，与其他所有能观测到该点云的关键帧中ORB描述子相比，该描述子的汉明距离最小。 根据ORB特征尺度不变性约束，可观测的点云的最大距离$d_{max}$和最小距离$d_{min}$。 对每个关键帧$K_i$保存以下信息： 相机位姿$T_{iw}$，从世界坐标系转换到相机坐标系下的变换矩阵。 相机内参，包括主点和焦距。 从图像帧提取的所有ORB特征，不管其是否已经关联了地图云点， 这些ORB特征点都经过畸变模型矫正过。  地图点云和关键帧的创建条件较为宽松，但是之后则会通过一个非常严格苛刻的删选机制进行挑选，该机制会检测出冗余的关键帧和匹配错误的或不可跟踪的云点进行删除。这样做的好处在于地图在构建过程中具有一定的弹性，在外界条件比较困难的情况下（比如：旋转，相机快速运动），算法仍然可以实现鲁棒的跟踪，而与此同时，当相机对同一个环境重访问时，地图的尺度大小是可控的，这就利于该系统的长期工作。另外，与PTAM算法相比，我们构建的地图中基本不包含局外点，因为秉持的原则是很苛刻的，宁缺毋滥。地图云点和关键帧的筛选过程将在第6部分B节和E节分别解释。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:3:3","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"D. Covisibility Graph和Essential Graph  关键帧之间的Covisibility信息在本文的SLAM系统中几个模块上都非常有用，像论文[7]一样，我们将其表示成一个间接的权重图。图中每个节点代表一个关键帧，如果两个关键帧都能同时观测到地图云点中至少15个点，则这两个关键帧之间用一条边线相连，我们用权重θ表示两个关键帧能共同观测到的云点数量。  为了矫正闭环回路，我们像论文[6]那样做位姿图优化，优化方法延着位姿图将闭环回路的误差进行分散。考虑到covisibility graph可能非常密集的边缘，我们提出构建一个（Essential Graph），该图中包含covisibility graph的所有节点（关键帧），但是边缘更少，仍旧保持一个强大的网络以获得精确的结果。系统从初始关键帧开始增量式地构建一个生成树，它是一个边缘数量最少的covisibility graph的子图。当插入新的关键帧时，则判断其与树上的关键帧能共同观测到多少云点，然后将其与共同观测点最多的关键帧相连反之，当一个关键帧通过筛选策略被删除时，系统会重新更新与其相关的连接。Essential Graph包含了一个生成树，一个高covisibility（$θ_{min}=100$）的covisibility graph边缘子集，以及闭环回路的边缘，这样的组合共同构建了一个强大的相机网络。图2展示了一个covisibility graph，生成树和相关的essential graph的例子。在本文第8部分第E节的实验里，当算法运行位姿图优化时，结果可以达到非常高的精度以至于即便是全局BA优化都很难达到。。essential graph的效用和θmin对算法的影响将在第8部分E节的最后讨论。 图2.对TUM RGB-D标准库[38]中fr3_long_office_household图像序列进行重构以及本文用到的各种姿态图的例子 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:3:4","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"E. 基于图像词袋模型的位置识别  为了实现闭环检测与重定位，系统嵌入了基于DBoW2[5]算法来执行闭环检测和重定位。视觉词汇（Visual words）是一个离散化的特征描述子空间，被称为视觉词典。这部视觉词典是通过从大量图像中提取ORB描述子离线创建的。如果图像的通用性强，则同一部视觉词典在不同的环境下也能获得很好的性能，正如我们之前的论文[11]那样。SLAM系统增量式地构建一个数据库，该数据库中包含了一个反向指针，用于存储每个视觉词典里的视觉单词，关键帧可以通过这个数据库查询视觉词典，从而实现高效检索。当一个关键帧通过筛选程序删除时，数据库也会相应更新。  由于关键帧之间可能会存在视图上的重叠，因此检索数据库时，可能返回的结果不止一个高分值的关键帧。原版的DBoW2认为是图像重叠的问题，就将时间上接近的图像的分值相加。但这并没有包括观测同一地点但在不同时间插入的关键帧。为了解决这一问题，我们将这些与covisibility graph相连的关键帧进行分类。另外，我们的数据库返回的是分值高于最好分值75%的所有关键帧。  用词袋模型来表示特征匹配的另外一个优势在论文[5]里有详细介绍。如果我们想计算两个ORB特征的对应关系，我们可以强制匹配视觉字典树上某一层（我们在6层里面选第2层）的相同节点（关键帧）里的特征，这可以加快搜索速度。在本文中，我们就利用这个小技巧来搜索匹配的特征点，用于三角化新的点云，闭环检测和重定位。我们还引入了方向一致性来优化匹配点，如论文[11]所示，这可以去掉无效数据，保证所有对应匹配点的旋转方向一致。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:3:5","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"IV.地图自动初始化  地图初始化的目的是计算两帧图像之间的相对位姿来三角化一组初始的地图云点。这个方法应该与场景无关（平面的一般平面），而且不需要人工干预去选择良好的双视图配置，比如两幅图应具有明显的视差。本文算法提出并行计算两个几何模型，一个是面向平面视图的单映矩阵，另一个是面向非平面视图的基础矩阵。然后，采用启发式的方法选择模型，并使用所选的模型从两图像的相对位姿中对地图点云进行重构。本文算法只有当两个视图之间的视差达到安全阈值时，才进行地图初始化。如果检测到低视差的情况或已知两视图模糊的情况（如论文[27]所示），则为了避免生成一个有缺陷的地图而推迟初始化。算法的步骤是：  1）查找初始的匹配点对：  从当前帧中提取ORB特征$F_c$（只在最好的尺度上），与在参考帧$F_r$搜索匹配点对$x_c$↔$x_r$。如果找不到足够的匹配点对，就重置参考帧。  2）并行计算两个模型：  在两个线程上并行计算单应矩阵$H_{cr}$和基础矩阵$F_{cr}$： $$ x_c=H_{cr}x_r{\\quad}{\\quad}{\\quad}{\\quad}x_c^TF_{cr}x_r=0 \\tag {1} $$ 在文献[2]中详细解释了基于RANSAC的归一化DLT算法和8点算法计算原理。为了使两个模型的计算流程尽量一样，将两个模型的迭代循环次数预先设置成一样，每次迭代的特征点数目也预先设置好，基础矩阵是8个特征点对，单映矩阵是4个特征点对。每次迭代中，我们给每个模型M（H表示单映射，F表示基本矩阵）计算一个分值SM： $$ S_{M}=\\sum_{i}\\left(\\rho_{M}\\left(d_{c r}^{2}\\left(\\mathbf{x}_{c}^{i}, \\mathbf{x}_{r}^{i}, M\\right)\\right)+\\rho_{M}\\left(d_{r c}^{2}\\left(\\mathbf{x}_{c}^{i}, \\mathbf{x}_{r}^{i}, M\\right)\\right)\\right) \\newline \\rho_{M}\\left(d^{2}\\right)=\\begin{cases} \\Gamma-d^{2} \u0026 \\text { if } \u0026 d^{2}\u003cT_{M} \\newline 0 \u0026 \\text { if } \u0026 d^{2} \\geq T_{M} \\end{cases} \\tag {2} $$ 其中，$d_{cr}^2$和$d_{rc}^2$是帧到帧之间的对称传递误差[2]。$T_M$是无效数据的排除阈值，它的依据是$\\chi^2$测试的95%（$T_H$=5.99，$T_F$=3.84，假设在测量误差上有1个像素的标准偏差）。$\\Gamma$等于$T_H$，这样两个模型在有效数据上对于同一误差$d$的分值相同，使得运算流程一致。  我们从单应矩阵和基本矩阵的计算中选择分值最高的，但如果两个模型分值都不高（没有足够的局内点），则算法流程重启，从step1开始重新计算。  3）模型选择：  如果场景是平面，近平面或存在低视差的情况，则可以通过单映矩阵来求解。同样地，我们也可以找到一个基础矩阵，但问题是基础矩阵不能够很好的约束该问题[2]，而且从基础矩阵中计算得到的运动结果是错误的。在这种情况下，我们应该选择单映矩阵才能保证地图初始的正确性，或者如果检测到低视差的情况则不进行初始化工作。另一方面，对于非平面场景且有足够的视差的情况则可以通过基础矩阵来计算，而在这种情况下单映矩阵只有基于平面点或者低视差的匹配点才能找到。因此，在这种情况下我们应该选择基础矩阵。我们利用如下强大的启发式进行计算： $$ R_{H}=\\frac{S_{H}}{S_{H}+S_{F}} \\tag{3} $$ 如果$R_H$\u003e0.45，这表示二维平面和低视差的情况，我们将选择计算单应矩阵。其他的情况，我们选择基础矩阵。 4）运动和从运动到结构的重构：  一旦选好模型，我们就可以获得相应的运动状态。如果是单应矩阵，我们按照Faugeras等人发表的论文[23]中提到的方法得到8种运动假设。该方法提出用cheriality测试来选择有效解。然而，如果在低视差的情况下，这些测试就会失效，因为云点很容易在相机的前面或后面移动，会导致选解错误。我们提出直接根据这8种解来进行三角化，然后检查是否有一种解可以使得所有的云点都位于两个相机的前面，且重投影误差较小。如果没有一个明确的解胜出，我们就不执行初始化，重新从第一步开始。这种方法使初始化程序在低视差和两个交叉的视图情况下更具鲁棒性，这也是我们整个算法体现鲁棒性的关键所在。  如果是基本矩阵，我们使用标定矩阵$K$来将其转换为本质矩阵： $$ E_{r c}={K}^{T} {F}_{r c} {K} \\tag {4} $$ 然后通过文献[4]中的奇异值分解得到4个运动解。和上文一样，通过三角化特征点，来选择一个正解。  5）Bundle adjustment：  最后我们执行一个全局BA，详细优化过程参见附录，以优化初始重构得到的点云地图。  如图3所示是对论文[39]中的室外NewCollege机器人图像序列进行地图初始化的例子，室外环境下初始化工作具有很大挑战性。从图中可以看出，PTAM算法和LSD-SLAM算法对位于同一平面上的所有点都进行了初始化，而我们的方法是当两幅图像有足够视差之后才进行初始化，并基于基础矩阵得到了正确的结果。 图3.基于NewCollege图像序列[39]进行地图初始化，最上面一行：PTAM算法,中间一行：LSD-SLAM算法，底下一行：ORB-SLAM算法。其中，PTAM算法和LSD-SLAM算法初始化了一个错误的平面地图，而我们的方法自动选择在两帧图像存在足够视差的情况下再利用基础矩阵初始化。如果人工选择关键帧，则PTAM算法也能够初始化得很好 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:4:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"V.跟踪  在这一部分，我们将详细介绍跟踪线程在相机每帧图像上执行的步骤。在几个步骤中都提到的相机位姿优化，包括运动BA，将在附录部分进行阐述。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:5:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"A. ORB特征提取  我们在8层图像金字塔上提取FAST角点，金字塔图像尺度因子为1.2。如果图像的分辨率从512*384到752*480，我们发现提取1000个角点比较合适，如果分辨率提高，如KITTI数据集[40]，则提取2000个角点。为了确保特征点均匀分布，我们将每层图像分成网格，每格提取至少5个角点。然后检测每格角点，如果角点数量不够，就调整阈值。如果某些单元格内没有角点，则其对应提取的角点数量也相应减少。最后，根据保留的FAST的角点计算方向和ORB特征描述子。ORB特征描述子将用于算法后续所有的特征匹配，而不是像PTAM算法中那样根据图像区块的相关性进行搜索。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:5:1","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"B. 通过前一帧估计初始位姿  如果上一帧图像跟踪成功，我们就用运动速率恒定模型来预测当前相机的位置，然后搜索上一帧图像中的特征点在地图中的对应云点与当前帧图像的匹配点，最后利用搜索到的匹配点对当前相机的位姿进一步优化。但是，如果没有找到足够的匹配点（比如，运动模型失效，非匀速运动），我们就加大搜索范围，搜索地图云点附近的点在当前帧图像中是否有匹配点，然后通过寻找到的对应匹配点对来优化当前时刻的相机位姿。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:5:2","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"C. 通过全局重定位开初始化位姿  如果扩大了搜索范围还是跟踪不到特征点，（那么运动模型已经失效），则计算当前帧图像的词袋（BoW）向量,并利用BoW词典选取若干关键帧作为备选匹配帧（这样可以加快匹配速度）。然后我们计算每个备选关键帧与地图云点相对应的ORB特征，如第三部分E节所描述。接着，对每个备选关键帧轮流执行PnP算法[41]计算当前帧的位姿（RANSAC迭代求解）。如果我们找到一个姿态能涵盖足够多的有效点，则搜索该关键帧对应的更多匹配云点。最后，基于找到的所有匹配点对相机位置进一步优化，如果有效数据足够多，则跟踪程序将持续执行。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:5:3","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"D. 跟踪局部地图  一旦我们获得了相机的初始位姿估计以及一组初始特征匹配点，我们就可以将更多地地图云点投影到图像上以寻找更多的匹配点。为了降低大地图的复杂性，我们只映射局部地图。该局部地图包含一组关键帧$K_1 $,它们和当前关键帧有共同的地图云点，还包括与关键帧$K_1$在covisibility graph中相邻的一组关键帧$K_2$。这个局部地图中有一个参考关键帧$K_{\\mathrm{ref}} \\in {K}_{1}$，它与当前帧具有最多共同的地图云点。现在对K1, K2中可见的每个地图云点，在当前帧中进行如下搜索：  1）计算地图点云在当前帧图像中的投影$\\mathrm{x}$，如果投影位置超出图像边缘，就将删去对应点云。  2）计算当前视图射线$v$和地图云点平均视图方向$\\mathbf{n}$的夹角。如果$\\mathbf{v} \\cdot \\mathbf{n}\u003c\\cos \\left(60^{\\circ}\\right)$，就删去对应点云。  3）计算地图点云到相机中心的距离$\\mathrm {d}$，如果它不在地图点云的尺度不变区间内，即$d \\notin\\left[d_{\\min }, d_{\\max }\\right]$，就删去该电云。  4）计算每帧图像的尺度比$d / d_{\\min }$。  5）对比地图云点的特征描述子$D$和当前帧中还未匹配的ORB特征，在预测的尺度层和靠近$\\mathrm{x}$的云点作最优匹配。  相机位姿最后通过当前帧中获得所有的地图云点进行优化。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:5:4","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"E. 新关键帧的判断  最后一步是决定当前帧是否可以作为关键帧。由于局部地图构建的过程中有一个机制去筛选冗余的关键帧，所以我们需要尽快地插入新的关键帧以保证跟踪线程对相机的运动更具鲁棒性，尤其是对旋转运动。我们根据以下要求插入新的关键帧：  1）距离上一次全局重定位后需要超过20帧图像。  2）局部地图构建处于空闲状态，或距上一个关键帧插入后，已经有超过20帧图像。  3）当前帧跟踪少于50个地图云点。  4）当前帧跟踪少于参考关键帧$K_{ref}$云点的90%。  与PTAM中用关键帧之间的距离作为判断标准不同，我们加入一个最小的视图变换，如条件4。条件1 确保一个好的重定位，条件3保证好的跟踪。如果局部地图构建处于忙状态（条件2的后半部分）的时候插入关键帧，就会发信号去暂停局部BA，这样就可以尽可能快地去处理新的关键帧。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:5:5","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"VI.局部建图  这章我们将描述根据每个新的关键帧$K_i$。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:6:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"A. 关键帧插入  首先更新covisibility graph，具体包括：添加一个新的关键帧节点$K_i$，检查与$K_i$有共同云点的其他关键帧，用边线连接。然后，更新生成树上与$K_i$有最多共享点的其他关键帧的链接。计算表示该关键帧的词袋，并利用三角法生成新的地图云点。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:6:1","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"B. 地图点云筛选  地图点云为了保留在地图里，必须在其创建后的头三个关键帧通过一个严格的测试，这个测试确保留下来的点云都是可以被跟踪的，而不是因为错误错误数据而被三角化创建的。一个云点必须满足如下条件： 跟踪线程必须必须在超过25%的图像中找到该特征点。 如果创建地图云点经过了多个关键帧，那么它必须至少是能够被其他3个关键帧观测到。  一旦一个地图云点通过测试，它只能在被少于3个关键帧观测到的情况下移除。这样的情况在关键帧被删除以及局部BA排除异值点的情况下发生。这个策略使得我们的地图包含很少的无效数据。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:6:2","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"C. 新地图点云创建  新的地图云点的创建是通过对covisibility graph中连接的关键帧$K_c$中的ORB特征点进行三角化实现的。对于$K_i$每个未匹配的ORB特征，我们在其他关键帧的未匹配点中进行查找，看是否有匹配上的特征点。这个匹配过程在第三部分第E节中有详细阐述，然后将那些不满足极线约束的匹配删除。ORB特征点对三角化后，需要对其在摄像头坐标系中的深度信息，视差，重投影误差和尺度一致性进行审查，通过后则将其作为新点插入地图。起初，一个地图云点通过2个关键帧观测，但它在其他关键帧中也有对应匹配点，所以它可以映射到其他相连的关键帧中，搜索算法的细则在本文第5部分D节中有讲述。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:6:3","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"D. 局部BA  局部BA主要优化当前处理的关键帧$K_i$，以及所有在covisibility graph里与$K_i$相连接的关键帧$K_c$，以及所有这些关键帧观测到的地图云点。所有其他能够观测到这些云点的关键帧，但没有连接$K_i$的会被保留在优化线程中，但保持不变。优化期间以及优化后，所有被标记为无效的观测数据都会被丢弃，附录有详细的优化细节。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:6:4","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"E. 局部关键帧筛选  为了使重构保持简洁，局部地图构建尽量检测冗余的关键帧，删除它们。这样不仅对BA过程会有很大帮助，因为随着关键帧数量的增加，BA优化的复杂度也随之增加，而且这能够在同一场景下运行下，关键帧的数量维持一个有限的数量。除非只有当场景内容改变了，关键帧的数量才会增加。这样一来，就增加了系统的可持续操作性。如果关键帧$K_c$中90%的点都可以被其他至少三个关键帧同时观测到，那认为Kc的存在是冗余的，我们则将其删除。这个尺度条件确保地图点拥有最精确测量的关键帧。这个策略受Tan等人的工作[24]的启发，在这项工作中，作者在经过一系列变化检测后即将关键帧删除。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:6:5","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"VII. 回环检测  闭环检测线程抽取$K_i$，即最后一帧局部地图关键帧，尝试用于检测以及闭合回环。具体步骤如下： ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:7:0","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"A. 候选关键帧  我们先计算$K_i$的词袋向量和它在covisibility graph中相邻图像（$θ_{min}=30$）的相似度，保留最低分值$s_{min}$。然后，我们检索图像识别数据库，丢掉那些分值低于$s_{min}$的关键帧。这和DBoW2中均值化分值的操作类似，可以获得好的鲁棒性，DBoW2中计算的是前一帧图像，而我们是使用的covisibility信息。此外，所有连接到Ki的关键帧都会从结果中删除。为了获得候选回环，我们必须检测3个一致的候选回环（covisibility graph中相连的关键帧）。如果对$K_i$来说环境样子都差不多，就可能有几个候选回环。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:7:1","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"B. 计算相似变换  单目SLAM系统有7个自由度，3个平移，3个旋转，1个尺度因子[6]。因此对于闭合回环，我们需要计算从当前关键帧$K_i$到回环关键帧$K_l$的相似变换，以获得回环的累积误差。计算相似变换也可以作为回环的几何验证。  我们先计算ORB特征关联的当前关键帧的地图云点和回环候选关键帧的对应关系，具体步骤如第3部分E节所示。此时，对每个候选回环，我们有了一个3D到3D的对应关系。我们对每个候选回环执行RANSAC迭代，通过Horn方法（如论文[42]）找到相似变换。如果我们用足够的有效数据找到相似变换$S_{il}$，我们就可以优化它，并搜索更多的对应关系。如果$S_{il}$有足够的有效数据，我们再优化它，直到$K_l$回环被接受。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:7:2","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"C. 回环融合  回环矫正的第一步是融合重复的地图云点，在covisibility graph中插入与回环相关的的新边缘。先通过相似变换$S_{il}$矫正当前关键帧位姿$T_{iw}$，这种矫正方法应用于所有与Ki相邻的关键帧，这样回环两端就可以对齐。然后，回环关键帧及其近邻能观测到的所有地图云点都映射到Ki及其近邻中，并在映射的区域附近小范围内搜索它的对应匹配点，如第5部分D节所述。所有匹配的地图云点和计算$S_{il}$过程中的有效数据进行融合。融合过程中所有的关键帧将会更新它们在covisibility graph中的边缘，创建的新边缘将用于回环检测。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:7:3","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["论文"],"content":"D. Essential Graph优化  为了有效地闭合回环，我们通过Essential Graph优化位姿图，如第三部分D节所示，这样可以将回环闭合的误差分散到图像中去。优化程序通过相似变换来校正尺度偏移，如论文[6]。误差和成本计算如附录所示。优化过后，每一个地图云点都根据关键帧的校正进行变换。 ","date":"2021-09-19","objectID":"/zh-cn/orb-slam/:7:4","tags":["翻译","论文","SLAM"],"title":"ORB-SLAM-译","uri":"/zh-cn/orb-slam/"},{"categories":["slam"],"content":"SLAM相关论文综合 ","date":"2021-09-17","objectID":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/:0:0","tags":["综述"],"title":"论文综述","uri":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"categories":["slam"],"content":"ORB-SLAM、ORB-SLAM2 目前最经典的基于特征点的视觉SLAM ","date":"2021-09-17","objectID":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/:1:0","tags":["综述"],"title":"论文综述","uri":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"categories":["slam"],"content":"DSO 目前最经典的基于直接法的视觉slam 在DSO中，提出了一种稀疏的、直接的单目视觉里程测量方法。完全直接的方法，联合优化所有涉及的模型参数的完全可能性，包括相机姿态，相机本质，和几何参数(反深度值)。与混合方法(SVO)形成对比，后者回归到联合模型优化的间接公式。 ","date":"2021-09-17","objectID":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/:2:0","tags":["综述"],"title":"论文综述","uri":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"categories":["slam"],"content":"SVO 半直接法视觉slam ","date":"2021-09-17","objectID":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/:3:0","tags":["综述"],"title":"论文综述","uri":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"categories":["slam"],"content":"LOAM 激光雷达SLAM ","date":"2021-09-17","objectID":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/:4:0","tags":["综述"],"title":"论文综述","uri":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"categories":["slam"],"content":"DEMO 同LOAM作者，视觉和激光雷达融合深度增强视觉里程计 ","date":"2021-09-17","objectID":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/:5:0","tags":["综述"],"title":"论文综述","uri":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"categories":["slam"],"content":"DVL-SLAM 视觉和激光雷达融合深度增强视觉里程计，直接法 ","date":"2021-09-17","objectID":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/:6:0","tags":["综述"],"title":"论文综述","uri":"/zh-cn/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"categories":null,"content":" Hugo 主题 FeelItHugo 主题 FeelIt \" Hugo 主题 FeelIt ","date":"2019-08-02","objectID":"/zh-cn/about/:0:0","tags":null,"title":"关于 FeelIt","uri":"/zh-cn/about/"},{"categories":null,"content":"特性 性能和 SEO  性能优化：在 Google PageSpeed Insights 中， 99/100 的移动设备得分和 100/100 的桌面设备得分  使用基于 JSON-LD 格式 的 SEO SCHEMA 文件进行 SEO 优化  支持 Google Analytics  支持 Fathom Analytics  支持 GoatCounter Analytics  支持搜索引擎的网站验证 (Google, Bind, Yandex and Baidu)  支持所有第三方库的 CDN  基于 lazysizes 自动转换图片为懒加载 外观和布局 / 响应式布局 / 浅色/深色 主题模式  全局一致的设计语言  支持分页  易用和自动展开的文章目录  支持多语言和国际化  美观的 CSS 动画 社交和评论系统  支持 Gravatar 头像  支持本地头像  支持多达 64 种社交链接  支持多达 28 种网站分享  支持 Disqus 评论系统  支持 Gitalk 评论系统  支持 Valine 评论系统  支持 Vssue 评论系统  支持 Facebook 评论系统  支持 Telegram comments 评论系统  支持 Commento 评论系统  支持 Utterances 评论系统 扩展功能  支持基于 Lunr.js 或 algolia 的搜索  支持 Twemoji  支持代码高亮  一键复制代码到剪贴板  支持基于 lightgallery.js 的图片画廊  支持 Font Awesome 图标的扩展 Markdown 语法  支持上标注释的扩展 Markdown 语法  支持分数的扩展 Markdown 语法  支持基于 $ \\KaTeX $ 的数学公式  支持基于 mermaid 的图表 shortcode  支持基于 ECharts 的交互式数据可视化 shortcode  支持基于 Mapbox GL JS 的 Mapbox shortcode  支持基于 APlayer 和 MetingJS 的音乐播放器 shortcode  支持 Bilibili 视频 shortcode  支持多种注释的 shortcode  支持自定义样式的 shortcode  支持自定义脚本的 shortcode  支持基于 TypeIt 的打字动画 shortcode  支持基于 cookieconsent 的 Cookie 许可横幅 … ","date":"2019-08-02","objectID":"/zh-cn/about/:0:1","tags":null,"title":"关于 FeelIt","uri":"/zh-cn/about/"},{"categories":null,"content":"许可协议 FeelIt 根据 MIT 许可协议授权。 更多信息请查看 LICENSE 文件。 FeelIt 主题中用到了以下项目，感谢它们的作者： modern-normalize Font Awesome Simple Icons Animate.css autocomplete.js Lunr.js algoliasearch lazysizes object-fit-images Twemoji lightgallery.js clipboard.js Sharer.js TypeIt $ \\KaTeX $ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine Vssue cookieconsent ","date":"2019-08-02","objectID":"/zh-cn/about/:0:2","tags":null,"title":"关于 FeelIt","uri":"/zh-cn/about/"}]